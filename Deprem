# earthquake_risk_gui.py
import threading
import time
import logging
import sys
import os
import datetime
import requests
import pandas as pd
import numpy as np
from geopy.distance import geodesic
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report
import tkinter as tk
from tkinter import scrolledtext, messagebox
import winsound
import warnings
warnings.filterwarnings('ignore')

# try xgboost
try:
    import xgboost as xgb
    XGB_AVAILABLE = True
except Exception:
    XGB_AVAILABLE = False

# ---------- AYARLAR ----------
KOERI_URL = "http://www.koeri.boun.edu.tr/scripts/lasteq.asp"
LIVE_DATA_PATH = "live_koeri.csv"
HISTORIC_DATA_PATH = "historic_earthquakes.csv"
CACHE_EXPIRY_MINUTES = 120
LOG_FILE = "earthquake_risk.log"
SLEEP_SECONDS = 180  # 3 dakika

BASE_CITIES = ["Istanbul", "Ankara", "Izmir", "Bursa", "Adana", "Malatya", "Balikesir", "Gaziantep","Van","Hatay"] 
ASSIGN_RADIUS_KM = 300
PREDICTION_WINDOW_DAYS = 20

# ---------- LOGGING ----------
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s | %(levelname)s | %(message)s",
    handlers=[logging.FileHandler(LOG_FILE), logging.StreamHandler(sys.stdout)]
)

# ---------- YARDIMCI FONKSİYONLAR ----------

def safe_float_conversion(value, default=np.nan):
    """Güvenli float dönüşümü"""
    try:
        return float(value)
    except (ValueError, TypeError):
        return default

def alert_large_earthquakes(app, df):
    """Büyük depremler için uyarı ver"""
    if df is None or df.empty:
        return
        
    large_eq = df[df['ML'] >= 4.6]
    if not large_eq.empty:
        cities = large_eq['City'].unique()
        message = "!!! ÖNEMLİ UYARI: 4.6+ Şiddetinde Deprem !!!\n"
        message += "Şehir(ler): " + ", ".join(cities) + "\n"
        app.display_text(message)

        # Bip sesi çıkar (Windows)
        try:
            for _ in range(2):
                winsound.Beep(1000, 500)
                time.sleep(0.2)
        except Exception:
            pass  # Ses çalma hatası

def closest_city(lat, lon, city_coords=None, radius_km=ASSIGN_RADIUS_KM):
    """En yakın şehri bul"""
    if city_coords is None:
        city_coords = {
            "Istanbul": (41.0082, 28.9784),
            "Ankara":   (39.9334, 32.8597),
            "Izmir":    (38.4237, 27.1428),
            "Bursa":    (40.1828, 29.0660),
            "Adana":    (37.0000, 35.3213),
            "Malatya":  (38.3556, 38.3094),
            "Balikesir":(39.6494, 27.8866),
            "Gaziantep":(37.0662, 37.3833),
            "Van":      (38.5019, 43.4167),
            "Hatay":    (36.2028, 36.1600)
        }
    
    min_dist = float('inf')
    chosen_city = "Other"
    
    for city, (clat, clon) in city_coords.items():
        try:
            d = geodesic((lat, lon), (clat, clon)).km
        except Exception:
            continue
        if d < min_dist:
            min_dist = d
            chosen_city = city
            
    return chosen_city if min_dist <= radius_km else "Other"

def assign_city(df):
    """DataFrame'e şehir bilgisi ata"""
    if df is None or df.empty:
        return df
        
    df = df.copy()
    
    # Coordinates üzerinden şehir atama
    if 'Latit' in df.columns and 'Long' in df.columns:
        df['City'] = df.apply(lambda r: closest_city(r['Latit'], r['Long']), axis=1)
    else:
        # Fallback: string içerikten şehir bulma
        df['City'] = 'Other'
        if 'place' in df.columns:
            for city in BASE_CITIES:
                df.loc[df['place'].str.contains(city, case=False, na=False), 'City'] = city
                
    return df

# ---------- VERI ÇEKME ----------

def is_cache_valid(path):
    """Önbelleğin geçerli olup olmadığını kontrol et"""
    if not os.path.exists(path):
        return False
    try:
        mod_time = datetime.datetime.fromtimestamp(os.path.getmtime(path))
        return (datetime.datetime.now() - mod_time) < datetime.timedelta(minutes=CACHE_EXPIRY_MINUTES)
    except Exception:
        return False

def fetch_koeri_data():
    """KOERI canlı verisini al; önbellek kullan"""
    if is_cache_valid(LIVE_DATA_PATH):
        try:
            logging.info("Önbellekten canlı veri okunuyor.")
            return pd.read_csv(LIVE_DATA_PATH, parse_dates=['Datetime'])
        except Exception as e:
            logging.warning(f"Önbellek okunamadı: {e}. Yeniden indirilecek.")

    logging.info("KOERI verisi indiriliyor...")
    try:
        r = requests.get(KOERI_URL, timeout=15)
        r.raise_for_status()
        text = r.text
    except Exception as e:
        logging.error(f"KOERI verisi indirilemedi: {e}")
        if os.path.exists(LIVE_DATA_PATH):
            logging.warning("Önbellekten eski canlı veri yüklenecek.")
            try:
                return pd.read_csv(LIVE_DATA_PATH, parse_dates=['Datetime'])
            except Exception:
                return None
        return None

    # Parse KOERI text format
    lines = text.splitlines()
    eq_lines = [ln.strip() for ln in lines if ln.strip().startswith("20")]
    cols = ["Date","Time","Latit","Long","Depth","MD","ML","Mw","Region"]
    rows = []

    for ln in eq_lines:
        try:
            parts = ln.split()
            if len(parts) < 9:
                continue
                
            date_s, time_s = parts[0], parts[1]
            lat = safe_float_conversion(parts[2])
            lon = safe_float_conversion(parts[3])
            depth = safe_float_conversion(parts[4])
            md = safe_float_conversion(parts[5])
            ml = safe_float_conversion(parts[6])
            mw = safe_float_conversion(parts[7])
            region = " ".join(parts[8:])
            
            rows.append([date_s, time_s, lat, lon, depth, md, ml, mw, region])
        except Exception as e:
            logging.warning(f"Satır işlenemedi: {ln} - Hata: {e}")
            continue

    if not rows:
        logging.warning("KOERI'den veri çıkmadı.")
        return None

    df = pd.DataFrame(rows, columns=cols)
    df['Datetime'] = pd.to_datetime(df['Date'] + ' ' + df['Time'], format="%Y.%m.%d %H:%M:%S", errors='coerce')
    df.drop(columns=['Date','Time'], inplace=True)
    df = df.dropna(subset=['Datetime']).reset_index(drop=True)
    df = df[(df['Latit'].between(-90,90)) & (df['Long'].between(-180,180))]
    df['ML'] = df['ML'].fillna(df['Mw'])
    df = df.rename(columns={'Region':'place'})
    
    try:
        df.to_csv(LIVE_DATA_PATH, index=False)
        logging.info(f"Canlı veri kaydedildi ({len(df)} satır) -> {LIVE_DATA_PATH}")
    except Exception as e:
        logging.error(f"Veri kaydedilemedi: {e}")
        
    return df

def load_historic_data():
    """Tarihsel veriyi yükle"""
    if not os.path.exists(HISTORIC_DATA_PATH):
        logging.warning("historic_earthquakes.csv bulunamadı; sadece canlı veri kullanılacak.")
        return None
        
    try:
        df = pd.read_csv(HISTORIC_DATA_PATH, parse_dates=['time'])
    except Exception as e:
        logging.error(f"Geçmiş veri okunamadı: {e}")
        return None
        
    # Column mapping
    column_mapping = {
        'time': 'Datetime',
        'latitude': 'Latit',
        'longitude': 'Long',
        'depth_km': 'Depth',
        'magnitude': 'ML',
        'place': 'place'
    }
    
    # Sadece mevcut kolonları yeniden adlandır
    existing_columns = [col for col in column_mapping.keys() if col in df.columns]
    df.rename(columns={col: column_mapping[col] for col in existing_columns}, inplace=True)
    
    df = assign_city(df)
    logging.info(f"Geçmiş veri yüklendi: {len(df)} kayıt")
    return df

# ---------- ÖZELLİK ÇIKARIMI ----------

def prepare_dataset(df):
    """Veri setini model eğitimi için hazırla"""
    if df is None or df.empty:
        return pd.DataFrame()
        
    df = df.copy()
    df['Date'] = df['Datetime'].dt.floor('D')
    rows = []
    
    for city in df['City'].unique():
        city_df = df[df['City'] == city].copy()
        if city_df.empty:
            continue
            
        daily = city_df.groupby('Date').agg(
            count=('ML','count'),
            mean_ML=('ML','mean'),
            max_ML=('ML','max'),
            var_ML=('ML','var'),
            mean_depth=('Depth','mean')
        ).reset_index()
        
        if daily.empty:
            continue
            
        # Tüm günleri içeren tam bir zaman serisi oluştur
        all_days = pd.date_range(daily['Date'].min(), daily['Date'].max(), freq='D')
        daily = daily.set_index('Date').reindex(all_days, fill_value=0).rename_axis('Date').reset_index()
        
        # NaN değerleri doldur
        daily['var_ML'] = daily['var_ML'].fillna(0)
        daily['mean_ML'] = daily['mean_ML'].fillna(0)
        daily['max_ML'] = daily['max_ML'].fillna(0)
        daily['mean_depth'] = daily['mean_depth'].fillna(0)
        
        # Hedef değişken: önümüzdeki PREDICTION_WINDOW_DAYS gün içinde deprem olup olmaması
        daily['target'] = daily['count'].rolling(window=PREDICTION_WINDOW_DAYS, min_periods=1).sum().shift(-PREDICTION_WINDOW_DAYS+1) > 0
        daily['target'] = daily['target'].fillna(False).astype(int)
        
        # Özellik mühendisliği - MEVCUT
        window = 30
        daily['feat_count_30d'] = daily['count'].rolling(window, min_periods=1).sum().shift(1).fillna(0)
        daily['feat_mean_ML_30d'] = daily['mean_ML'].rolling(window, min_periods=1).mean().shift(1).fillna(0)
        daily['feat_max_ML_30d'] = daily['max_ML'].rolling(window, min_periods=1).max().shift(1).fillna(0)
        daily['feat_var_ML_30d'] = daily['var_ML'].rolling(window, min_periods=1).mean().shift(1).fillna(0)
        daily['feat_mean_depth_30d'] = daily['mean_depth'].rolling(window, min_periods=1).mean().shift(1).fillna(0)
        
        # YENİ ÖZELLİKLER - EKLENDİ
        daily['feat_seismic_activity'] = (daily['count'] > 0).rolling(7, min_periods=1).mean().shift(1).fillna(0)
        daily['feat_large_eq_count'] = (daily['max_ML'] > 4.0).rolling(30, min_periods=1).sum().shift(1).fillna(0)
        daily['feat_depth_variance'] = daily['mean_depth'].rolling(30, min_periods=1).std().shift(1).fillna(0)
        daily['feat_recent_activity'] = daily['count'].rolling(7, min_periods=1).sum().shift(1).fillna(0)
        
        for _, r in daily.iterrows():
            rows.append({
                'City': city,
                'Date': r['Date'],
                'count': r['count'],
                'mean_ML': r['mean_ML'],
                'max_ML': r['max_ML'],
                'var_ML': r['var_ML'],
                'mean_depth': r['mean_depth'],
                'feat_count_30d': r['feat_count_30d'],
                'feat_mean_ML_30d': r['feat_mean_ML_30d'],
                'feat_max_ML_30d': r['feat_max_ML_30d'],
                'feat_var_ML_30d': r['feat_var_ML_30d'],
                'feat_mean_depth_30d': r['feat_mean_depth_30d'],
                # YENİ ÖZELLİKLER - EKLENDİ
                'feat_seismic_activity': r['feat_seismic_activity'],
                'feat_large_eq_count': r['feat_large_eq_count'],
                'feat_depth_variance': r['feat_depth_variance'],
                'feat_recent_activity': r['feat_recent_activity'],
                'target': r['target']
            })
            
    dataset = pd.DataFrame(rows)
    return dataset

# ---------- MODEL EĞİTİMİ ----------

def train_model(dataset):
    """Temel model eğitimi"""
    if dataset is None or dataset.empty:
        logging.warning("Boş veri seti, model eğitilemiyor.")
        return None
        
    dataset = dataset.dropna()
    dataset = dataset[dataset['City'] != "Other"]
    
    if len(dataset) < 10:
        logging.warning("Yeterli veri yok, model eğitilemiyor.")
        return None
        
    # GÜNCELLENMİŞ FEATURES LİSTESİ
    features = [
        'feat_count_30d', 'feat_mean_ML_30d', 'feat_max_ML_30d', 
        'feat_var_ML_30d', 'feat_mean_depth_30d',
        # YENİ ÖZELLİKLER
        'feat_seismic_activity', 'feat_large_eq_count', 
        'feat_depth_variance', 'feat_recent_activity'
    ]
    
    X = dataset[features]
    y = dataset['target']
    
    if len(y.unique()) < 2:
        logging.warning("Yeterli çeşitlilikte hedef yok, model eğitilemiyor.")
        return None

    # Model seçimi
    if XGB_AVAILABLE and len(dataset) > 100:
        model = xgb.XGBClassifier(
            use_label_encoder=False, 
            eval_metric='logloss', 
            random_state=42,
            n_estimators=200,
            max_depth=8,
            learning_rate=0.1,
            scale_pos_weight=2.0  # 3.0'dan 2.0'a düşürüldü
        )
    elif len(dataset) > 50:
        model = RandomForestClassifier(
            n_estimators=100,
            random_state=42,
            max_depth=7
        )
    else:
        model = LogisticRegression(max_iter=200, random_state=42)

    try:
        model.fit(X, y)
        logging.info(f"{model.__class__.__name__} modeli eğitildi. Veri boyutu: {len(dataset)}")
        return model
    except Exception as e:
        logging.error(f"Model eğitimi sırasında hata: {e}")
        return None

def train_model_advanced(dataset):
    """Gelişmiş model eğitimi ve değerlendirme"""
    if dataset is None or dataset.empty or len(dataset) < 100:
        return train_model(dataset)  # Basit modele fallback
        
    dataset = dataset.dropna()
    dataset = dataset[dataset['City'] != "Other"]
    
    if len(dataset) < 50:
        return train_model(dataset)
        
    # GÜNCELLENMİŞ FEATURES LİSTESİ
    features = [
        'feat_count_30d', 'feat_mean_ML_30d', 'feat_max_ML_30d', 
        'feat_var_ML_30d', 'feat_mean_depth_30d',
        # YENİ ÖZELLİKLER
        'feat_seismic_activity', 'feat_large_eq_count', 
        'feat_depth_variance', 'feat_recent_activity'
    ]
    
    X = dataset[features]
    y = dataset['target']
    
    # Train-test split
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )
    
    # Model seçimi
    if XGB_AVAILABLE:
        model = xgb.XGBClassifier(
            use_label_encoder=False,
            eval_metric='logloss',
            random_state=42,
            n_estimators=200,
            max_depth=8,
            learning_rate=0.1,
            scale_pos_weight=2.0  # 3.0'dan 2.0'a düşürüldü
        )
    else:
        model = RandomForestClassifier(
            n_estimators=150,
            random_state=42,
            max_depth=8
        )
    
    try:
        model.fit(X_train, y_train)
        
        # Model değerlendirme
        y_pred = model.predict(X_test)
        report = classification_report(y_test, y_pred)
        logging.info(f"Model değerlendirme:\n{report}")
        
        return model
    except Exception as e:
        logging.error(f"Gelişmiş model eğitimi hatası: {e}")
        return train_model(dataset)  # Fallback to simple model

# ---------- TAHMİN ----------

def predict_risk(model, dataset, cities=BASE_CITIES):
    """Risk tahmini yap"""
    if model is None or dataset is None or dataset.empty:
        return {city: 0.0 for city in cities}

    # GÜNCELLENMİŞ FEATURES LİSTESİ
    features = [
        'feat_count_30d', 'feat_mean_ML_30d', 'feat_max_ML_30d', 
        'feat_var_ML_30d', 'feat_mean_depth_30d',
        # YENİ ÖZELLİKLER
        'feat_seismic_activity', 'feat_large_eq_count', 
        'feat_depth_variance', 'feat_recent_activity'
    ]
    
    latest_date = dataset['Date'].max()
    risk = {}
    
    for city in cities:
        city_data = dataset[(dataset['City'] == city) & (dataset['Date'] == latest_date)]
        if city_data.empty:
            risk[city] = 0.0
            continue
            
        X = city_data[features]
        try:
            pred_prob = model.predict_proba(X)[:,1][0]
            risk[city] = min(max(pred_prob, 0.0), 1.0)  # 0-1 arasında sınırla
        except Exception as e:
            logging.error(f"{city} için tahmin yapılamadı: {e}")
            risk[city] = 0.0
            
    return risk

# ---------- GUI ----------

class EarthquakeRiskApp(tk.Tk):
    def __init__(self):
        super().__init__()
        self.title("Deprem Risk Tahmin Sistemi")
        self.geometry("500x400")
        self.configure(bg='white')
        
        # Pencere kapatma olayını yakala
        self.protocol("WM_DELETE_WINDOW", self.on_closing)

        # Ana frame
        main_frame = tk.Frame(self, bg='white')
        main_frame.pack(fill=tk.BOTH, expand=True, padx=10, pady=10)

        # Başlık
        title_label = tk.Label(main_frame, text="Deprem Risk Tahmin Sistemi", 
                              font=("Arial", 16, "bold"), bg='white')
        title_label.pack(pady=(0, 10))

        # Text area - Kopyalama özelliği için
        self.text = scrolledtext.ScrolledText(main_frame, font=("Arial", 11), 
                                            wrap=tk.WORD, height=15)
        self.text.pack(fill=tk.BOTH, expand=True, padx=5, pady=5)
        self.text.config(state=tk.DISABLED, bg='#f8f9fa')
        
        # Sağ tık menüsü ekle (kopyalama için)
        self.context_menu = tk.Menu(self, tearoff=0)
        self.context_menu.add_command(label="Kopyala", command=self.copy_text)
        self.text.bind("<Button-3>", self.show_context_menu)  # Sağ tık

        # Tag'ler renk için
        self.text.tag_configure("red", foreground="red", background='#f8f9fa', font=("Arial", 11, "bold"))
        self.text.tag_configure("yellow", foreground="orange", background='#f8f9fa', font=("Arial", 11))
        self.text.tag_configure("green", foreground="green", background='#f8f9fa', font=("Arial", 11))
        self.text.tag_configure("header", foreground="navy", background='#f8f9fa', font=("Arial", 12, "bold"))

        # Buton frame
        button_frame = tk.Frame(main_frame, bg='white')
        button_frame.pack(pady=10)

        # Manuel güncelleme butonu
        self.update_button = tk.Button(button_frame, text="Şimdi Güncelle", 
                                     command=self.manual_update, bg='#007bff', fg='white')
        self.update_button.pack(side=tk.LEFT, padx=5)

        # Çıkış butonu - DÜZELTİLDİ
        self.exit_button = tk.Button(button_frame, text="Çıkış", 
                                   command=self.on_closing, bg='#dc3545', fg='white')  # self.quit yerine self.on_closing
        self.exit_button.pack(side=tk.LEFT, padx=5)

        # Durum barı
        self.status_var = tk.StringVar()
        self.status_var.set("Hazır")
        status_bar = tk.Label(main_frame, textvariable=self.status_var, 
                            relief=tk.SUNKEN, anchor=tk.W, bg='white')
        status_bar.pack(side=tk.BOTTOM, fill=tk.X)

        self.update_risks()
        self.after(SLEEP_SECONDS * 1000, self.periodic_update)

    def show_context_menu(self, event):
        """Sağ tık menüsünü göster"""
        try:
            self.context_menu.tk_popup(event.x_root, event.y_root)
        finally:
            self.context_menu.grab_release()

    def copy_text(self):
        """Metni kopyala"""
        try:
            selected_text = self.text.get(tk.SEL_FIRST, tk.SEL_LAST)
            self.clipboard_clear()
            self.clipboard_append(selected_text)
        except tk.TclError:
            # Eğer metin seçili değilse, tüm metni kopyala
            self.text.config(state=tk.NORMAL)
            all_text = self.text.get(1.0, tk.END)
            self.clipboard_clear()
            self.clipboard_append(all_text)
            self.text.config(state=tk.DISABLED)

    def on_closing(self):
        """Pencere kapatma işlemi"""
        if messagebox.askokcancel("Çıkış", "Uygulamadan çıkmak istediğinize emin misiniz?"):
            self.destroy()  # self.quit() yerine self.destroy()

    def update_risks(self):
        """Risk güncelleme işlemi"""
        self.status_var.set("Veri alınıyor...")
        self.update_idletasks()
        
        try:
            live_df = fetch_koeri_data()
            historic_df = load_historic_data()

            if live_df is None:
                self.display_text("Canlı veri alınamadı.")
                self.status_var.set("Hata: Veri alınamadı")
                return

            # Büyük deprem uyarısı
            alert_large_earthquakes(self, live_df)

            # Veri birleştirme
            if historic_df is not None:
                combined_df = pd.concat([historic_df, live_df], ignore_index=True)
            else:
                combined_df = live_df.copy()

            combined_df = assign_city(combined_df)
            
            self.status_var.set("Veri işleniyor...")
            self.update_idletasks()
            
            dataset = prepare_dataset(combined_df)

            if dataset.empty:
                self.display_text("Veri seti boş, tahmin yapılamıyor.")
                self.status_var.set("Hata: Veri seti boş")
                return

            self.status_var.set("Model eğitiliyor...")
            self.update_idletasks()
            
            # Model seçimi
            if len(dataset) > 100:
                model = train_model_advanced(dataset)
            else:
                model = train_model(dataset)
                
            if model is None:
                self.display_text("Model eğitilemedi.")
                self.status_var.set("Hata: Model eğitilemedi")
                return

            self.status_var.set("Tahmin yapılıyor...")
            self.update_idletasks()
            
            risk = predict_risk(model, dataset)
            self.show_risk(risk)
            self.status_var.set(f"Güncellendi: {datetime.datetime.now().strftime('%H:%M:%S')}")
            
        except Exception as e:
            logging.error(f"Risk güncelleme hatası: {e}")
            self.status_var.set(f"Hata: {str(e)}")
            self.display_text(f"Hata oluştu: {str(e)}")

    def show_risk(self, risk):
        """Risk sonuçlarını göster"""
        self.text.config(state=tk.NORMAL)
        self.text.delete(1.0, tk.END)
        
        # Başlık
        self.text.insert(tk.END, f"Deprem Risk Tahminleri\n", "header")
        self.text.insert(tk.END, f"Son Güncelleme: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
        
        # Şehir riskleri
        for city in BASE_CITIES:
            val = risk.get(city, 0)
            val_pct = int(val * 100)
            
            if val >= 0.5:
                tag = "red"
                risk_text = "YÜKSEK RİSK"
            elif val >= 0.3:
                tag = "yellow"
                risk_text = "ORTA RİSK"
            else:
                tag = "green"
                risk_text = "DÜŞÜK RİSK"

            self.text.insert(tk.END, f"{city:12}: {val_pct:3d}% - {risk_text}\n", tag)

        # Açıklama
        self.text.insert(tk.END, f"\nNot: Tahminler son {PREDICTION_WINDOW_DAYS} günlük veriye dayanmaktadır.\n")
        self.text.insert(tk.END, f"Sonraki güncelleme: {SLEEP_SECONDS} saniye sonra\n")
        
        self.text.config(state=tk.DISABLED)

    def display_text(self, message):
        """Metin göster"""
        self.text.config(state=tk.NORMAL)
        self.text.delete(1.0, tk.END)
        self.text.insert(tk.END, message)
        self.text.config(state=tk.DISABLED)

    def periodic_update(self):
        """Periyodik güncelleme"""
        try:
            self.update_risks()
        except Exception as e:
            logging.error(f"Periyodik güncelleme hatası: {e}")
            self.status_var.set(f"Hata: {str(e)}")
        finally:
            self.after(SLEEP_SECONDS * 1000, self.periodic_update)

    def manual_update(self):
        """Manuel güncelleme"""
        self.update_button.config(state=tk.DISABLED)
        try:
            self.update_risks()
        finally:
            self.update_button.config(state=tk.NORMAL)

# ---------- PROGRAM BAŞLAT ----------

if __name__ == "__main__":
    try:
        app = EarthquakeRiskApp()
        app.mainloop()
    except Exception as e:
        logging.error(f"Uygulama hatası: {e}")
        messagebox.showerror("Hata", f"Uygulama başlatılamadı: {str(e)}")
